# PixelRNN-model-for-occulated-image-completion
Reconstruct occluded bedroom images using an optimized PixelRNN-based deep learning model. This project predicts missing image regions from intentionally masked inputs. Trained on paired occluded original datasets, it demonstrates effective image completion with analysis and performance evaluation.

# Occluded Image Reconstruction using Optimized PixelRNN with ConvLSTM

This project reconstructs occluded images of bedrooms using an optimized PixelRNN model integrated with ConvLSTM. It leverages both pixel-wise accuracy (MSE) and perceptual similarity (SSIM) to improve reconstruction quality, especially in structurally complex scenes.

## Overview

The model takes in occluded RGB images and attempts to reconstruct their original appearance. The solution is trained on paired bedroom images—occluded and original—and aims to predict missing or masked sections of the image.

## Features

- Custom PyTorch Dataset for paired image loading
- Optimized Encoder-Decoder PixelRNN with ConvLSTM for spatial memory
- Combined loss using MSE and SSIM for sharper and more coherent results
- Visualization of reconstruction results
- Training loss plotting over epochs

## Dataset

The dataset contains:
- `train/occluded_images`: Occluded images with missing regions
- `train/original_images`: Ground truth images
- `occluded_test/`: Test images with occlusions (no ground truth used during testing)

All images are resized to 256x256 during preprocessing.

## Model Architecture

- Encoder: CNN with increasing channels and downsampling for feature extraction
- ConvLSTMCell: Maintains spatial memory using convolutional gates, modeling spatial dependencies
- Decoder: PixelShuffle-based upsampling to reconstruct the full-resolution image

The model outputs RGB images of the same resolution as the input.

## Training

Run the training loop:

```bash
python train.py
```

Training configuration:

* Epochs: 20
* Batch size: 16
* Optimizer: Adam (learning rate 0.001)
* Loss: `combined_loss = 0.8 * MSE + 0.2 * (1 - SSIM)`

The trained model is saved to:

```
/kaggle/working/optimized_pixelrnn.pth
```

Loss over epochs is visualized using `matplotlib`.

## Evaluation

To visualize reconstructed images on the test set or your own occluded images, start the Streamlit frontend:

```bash
streamlit run app.py
```

This will launch a web interface where you can upload an occluded image. The app will display both the uploaded (occluded) image and the reconstructed image generated by the PixelRNN model.

Each occluded image will be displayed with its corresponding reconstruction.

## Results

* Clear enhancement of occluded image regions over time
* Reconstructed outputs retain structural details such as walls and large furniture
* Combined loss outperformed MSE-only models in perceptual quality
* Fine details such as textures were harder to fully recover but improved over training

## References

* [PixelRNN – van den Oord et al.](https://arxiv.org/abs/1601.06759)
* [ConvLSTM – Shi et al.](https://arxiv.org/abs/1506.04214)
* [PIQ (PyTorch Image Quality) Library](https://github.com/photosynthesis-team/piq)

## Requirements

- Python 3.8+
- torch
- torchvision
- Pillow
- matplotlib
- streamlit

Install the dependencies using:

```bash
pip install -r requirements.txt
```

## Running the Streamlit App

To visualize reconstructed images on the test set or your own occluded images, start the Streamlit frontend:

```bash
streamlit run app.py
```

This will launch a web interface where you can upload an occluded image. The app will display both the uploaded (occluded) image and the reconstructed image generated by the PixelRNN model.

Each occluded image will be displayed with its corresponding reconstruction.
